{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3b59c-52f3-4eb8-9957-dbe2792774d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 웹드라이버 설정\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 디버거 모드로 설정\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                          options=webdriver.ChromeOptions().add_experimental_option(\"debuggerAddress\",\"localhost:9222\"))\n",
    "\n",
    "site_url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EC%9E%90%EB%8F%99%EC%B0%A8&oquery=%EC%9E%90%EB%8F%99%EC%B0%A8&tqi=i6QNUwprvmZssfTsc00ssssssOK-244827'\n",
    "driver.get(site_url)\n",
    "\n",
    "hrefs = set()\n",
    "\n",
    "while True:\n",
    "    # 현재 페이지의 HTML을 가져옴\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 'div.info_box' 내의 'a' 태그를 찾아서 href 속성 저장\n",
    "    a_tags = soup.select('div.info_box a')\n",
    "    urls = [a['href'] for a in a_tags if 'href' in a.attrs]\n",
    "    new_hrefs = set(urls) - hrefs  # 이전에 가져온 href 정보와 중복된 것을 제외함\n",
    "    hrefs.update(new_hrefs)  # 새로운 href 정보를 추가\n",
    "\n",
    "    # 다음 페이지로 넘어감\n",
    "    try:\n",
    "        next_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//a[@class=\"pg_next on\"]')))\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        time.sleep(0.1)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03d9da-2bc2-4509-866a-ee60b9c39cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://search.naver.com/search.naver?'\n",
    "\n",
    "def parse_car_name_kind(html):\n",
    "    # 이름, 사진 갖고오기\n",
    "    # soup = BeautifulSoup(html, 'html.parser')\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    car_name = soup.select('span.area_text_title ._text')[0].text.strip()\n",
    "    car_img = soup.find(\"div\", class_=\"img_area\").find(\"img\").get(\"src\")\n",
    "    return  car_name, car_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5a4a5-33d9-4f92-b0ac-212d0f73bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"./car_img.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as fw:\n",
    "    writer = csv.writer(fw)\n",
    "    headers = [\"name\", \"img\"]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    for href in tqdm(hrefs):\n",
    "        full_url = base_url + href\n",
    "        driver.get(full_url)\n",
    "        car_name, car_img = parse_car_name_kind(driver.page_source)\n",
    "        car_info = [car_name, car_img]\n",
    "        writer.writerow(car_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
